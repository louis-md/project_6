{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "import pickle\n",
    "\n",
    "\n",
    "def getScaler(df):\n",
    "    scaler = StandardScaler()\n",
    "    audio_scaler = scaler.fit(df[[\"danceability\", \"energy\", \"loudness\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"]])\n",
    "    X_normalized = audio_scaler.transform(df[[\"danceability\", \"energy\", \"loudness\", \"speechiness\", \"acousticness\", \"instrumentalness\", \"liveness\", \"valence\", \"tempo\"]])\n",
    "    return X_normalized, audio_scaler\n",
    "\n",
    "X_normalized, audio_scaler = getScaler(df2)\n",
    "\n",
    "\n",
    "def getClusterIds(df):\n",
    "\n",
    "    # Predict clusters using KMeans\n",
    "    kmeans = KMeans(n_clusters=1000, n_init=10) # TODO: Find optimal number of clusters using an elbow graph\n",
    "    my_kmeans = kmeans.fit(df)\n",
    "    cluster_ids = my_kmeans.predict(df)\n",
    "    return cluster_ids, my_kmeans\n",
    "\n",
    "cluster_ids, my_kmeans = getClusterIds(X_normalized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"kmeans1000.pickle\", \"wb\") as f: #saves the model in dir and file name given\n",
    "    pickle.dump(my_kmeans,f)\n",
    "with open(\"scaler.pickle\", \"wb\") as f: #saves the model in dir and file name given\n",
    "    pickle.dump(audio_scaler,f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
